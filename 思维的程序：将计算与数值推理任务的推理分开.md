# 思维的程序：将计算与数值推理任务的推理分开

## 问题与背景

现有的语言模型对于实际解决复杂数学表达式并不理想，因为：

1. LLM 很容易出现算术计算错误，尤其是在处理大数时；

2. LLM无法求解多项式方程甚至微分方程等复杂的数学表达式；

3. LLM在表达迭代方面效率非常低，特别是当迭代步数很大时；

为了解决这些问题，作者认为可以将复杂的计算过程和llm的思维过程分离开，而将计算过程交给程序来完成，这样就可以提高模型在复杂表达式求解上的准确度。

## 本文方法

根据上述问题和思路，作者提出了program-of-thoughts (PoT)，和CoT直接推理求解整个问题的思维过程不同，借助CodeX，PoT选择将问题和求解过程表述为python程序，然后执行可解释的python程序得到答案。方法和CoT的对比如下：

<div align=center>
<img src=assets/image-20231009162301-lhjedhv.png height=500 width=600/>
</div>

不难看出，CoT在求解需要多部迭代才得到答案的问题时非常依赖中间每一步的正确结果，而PoT的结果直接由一个迭代程序给出；CoT无法处理高次方程，而PoT将方程用程序表达出来并将求解过程交给专用程序sympy。

在实际操作上，作者考虑了以下几种情况：

1. 程序的变量名应该具有实际意义，作者发现变量名有没有和实际问题中变量名绑定会给结果造成比较大的影响，并在实验中验证了。
2. 作者将复杂问题（如高次方程）转化为程序，并希望程序可以按照多步实现的方式求解最终答案。作者发现这种“深思熟虑”的过程可以激发语言模型的推理能力并生成更准确的程序。
3. 对于某些需要额外常识推理的问题，首先需要利用 PoT 生成一个程序来计算中间结果，然后结合问题继续促使 LLM 得出最终答案。
4. 作者对PoT进行了zero shot, few shot下的推理，并将PoT和self-consistency相结合，在PoT+SC的设置下得到了最好的结果。
<div align=center>
<img src=assets/image-20231009192312-78km4h2.png height=420 width=650/>
</div>

三，实验结果分析

作者在以下8个和数学推理相关数据集（其中有两个和金融领域相关的Fin数据集）上进行了实验，并和已有的sota以及CoT进行了对比。

<div align=center>
<img src=assets/image-20231009192655-50kur9t.png height=250 width=650/>
<img src=assets/image-20231009193213-w28wh1u.png height=500 width=650/>
</div>

在few-shot的设置下，作者的方法相比sota和cot均有提升，特别是在两个涉及金融领域的数据集上提升显著，作者认为这一改进源于之前llm对大量数据（例如数百万，浮点数）的错误计算。而在few-shot+sc的设置下，作者获得了超过当时sota的结果。

<div align=center>
<img src=assets/image-20231009193533-n0lt9ag.png/>
</div>

在零样本的设置下，PoT也能获得远超CoT的结果。

此外，作者还进行了以下消融实验：

1. 对比采用了专门针对代码生成进行优化的GPT模型CodeX和一般只针对文本进行优化的GPT之间在表现差异，显然针对代码生成进行过优化的CodeX的表现更好，特别是在比较难的数学推理数据集GSM8K上。
<div align=center>
<img src=assets/image-20231009194359-6lfbz2v.png height=250 width=400/>
</div>

2. 对比了有无变量名实际含义绑定和有无多步计算情况下PoT的表现差异，同样的，在比较难的数学推理数据集上，有无Binding和MultiStep的表现差别显著。
<div align=center>
<img src=assets/image-20231009194854-8lyv8my.png height=230 width=400/>
</div>

3. 最后一个是few-shot设置下，样例选择和数量对结果的影响，作者分析得出在更难的数据集上需要更多的提示样例PoT的表现才能更好。

四，总结，分析，反思

1. 作者针对复杂数学问题求解（复杂数，高次方程，微分方程等）提出了PoT，旨在将llm对问题的求解过程和复杂计算分离开，llm只需要将问题和求解过程转化为程序，而不必执行实际的计算过程。
2. PoT 最大的改进在于求解“线性/多项式方程”，“迭代”，“符号”和“组合数学”类别的数学问题，而其他的类别的数学问题和CoT表现近似。
<div align=center>
<img src=assets/image-20231009195740-qmihjir.png height=350 width=450/>
</div>

3. PoT的表现比较依赖于一个专门的基于自然语言的代码生成模型，如果换做是现在的codellama，表现可能
会更进一步。

4. 需要考虑下，在现有的数学问题中，如果存在有利用程序或着说python工具无法求解的问题，那么PoT的方法也会受限。

5. 本文给出了代码（包括在各类数学推理数据集实验的代码），这是一个比较好的基于GPT3做数学推理的样本。

‍
